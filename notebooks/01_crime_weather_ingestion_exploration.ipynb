{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09c7a0e5",
   "metadata": {},
   "source": [
    "# Notebook 01 – Data Ingestion & Initial Exploration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e521292d",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Environment Setup\n",
    "\n",
    "Ensuring a clean and reproducible environment is fundamental. Here, we import the core libraries and set up our workspace so that anyone cloning this repo can replicate our analysis without compatibility issues.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9decd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential imports\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f1eb97",
   "metadata": {},
   "source": [
    "# 2. Load Raw Data\n",
    "\n",
    "Loading raw datasets is the first critical step. By separating this phase, we maintain a clear pipeline: raw files remain untouched, enabling transparent version control and easy auditing of original sources.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84675124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading nypd_1.csv…\n",
      "Loading nypd_2.csv…\n",
      "Loading nypd_3.csv…\n",
      "Loading nypd_4.csv…\n",
      "Combined crime shape: (565118, 35)\n",
      "Weather shape: (366, 151)\n",
      "Boroughs shape: (5, 5)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1) Define raw data directory\n",
    "RAW_DIR = Path('..') / 'data' / 'raw'\n",
    "\n",
    "# 2) Find all NYPD CSV parts (nypd_1.csv, nypd_2.csv, …)\n",
    "crime_files = sorted(RAW_DIR.glob('nypd_*.csv'))\n",
    "\n",
    "# 3) Read each part into a DataFrame, parse the date, and collect\n",
    "crime_dfs = []\n",
    "for f in crime_files:\n",
    "    print(f\"Loading {f.name}…\")\n",
    "    df_part = pd.read_csv(\n",
    "        f,\n",
    "        parse_dates=['cmplnt_fr_dt'],   # your lowercase date column\n",
    "        low_memory=False\n",
    "    )\n",
    "    crime_dfs.append(df_part)\n",
    "\n",
    "# 4) Concatenate into one DataFrame\n",
    "df_crime = pd.concat(crime_dfs, ignore_index=True)\n",
    "print(\"Combined crime shape:\", df_crime.shape)\n",
    "\n",
    "# 5) Load weather and boroughs as before\n",
    "df_weather = pd.read_csv(\n",
    "    RAW_DIR / 'noaa_ghcnd_2024.csv',\n",
    "    parse_dates=['DATE'],\n",
    "    low_memory=False\n",
    ")\n",
    "print(\"Weather shape:\", df_weather.shape)\n",
    "\n",
    "gdf_boroughs = gpd.read_file(RAW_DIR / 'nyc_boroughs.geojson')\n",
    "print(\"Boroughs shape:\", gdf_boroughs.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a52bd4e",
   "metadata": {},
   "source": [
    "## 3. Initial Data Inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44be759",
   "metadata": {},
   "source": [
    "### 3.1 Data Types & Shapes\n",
    "\n",
    "Understanding the structure and scale of each dataset is key to planning the analysis. Checking data types and shapes helps identify conversion needs, memory constraints, and potential anomalies before diving deeper.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45484471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crime data shape: (565118, 35)\n",
      "cmplnt_num                   object\n",
      "cmplnt_fr_dt         datetime64[ns]\n",
      "cmplnt_fr_tm                 object\n",
      "cmplnt_to_dt                 object\n",
      "cmplnt_to_tm                 object\n",
      "addr_pct_cd                   int64\n",
      "rpt_dt                       object\n",
      "ky_cd                         int64\n",
      "ofns_desc                    object\n",
      "pd_cd                       float64\n",
      "pd_desc                      object\n",
      "crm_atpt_cptd_cd             object\n",
      "law_cat_cd                   object\n",
      "boro_nm                      object\n",
      "loc_of_occur_desc            object\n",
      "prem_typ_desc                object\n",
      "juris_desc                   object\n",
      "jurisdiction_code             int64\n",
      "parks_nm                     object\n",
      "hadevelopt                   object\n",
      "housing_psa                 float64\n",
      "x_coord_cd                  float64\n",
      "y_coord_cd                  float64\n",
      "susp_age_group               object\n",
      "susp_race                    object\n",
      "susp_sex                     object\n",
      "transit_district            float64\n",
      "latitude                    float64\n",
      "longitude                   float64\n",
      "lat_lon                      object\n",
      "patrol_boro                  object\n",
      "station_name                 object\n",
      "vic_age_group                object\n",
      "vic_race                     object\n",
      "vic_sex                      object\n",
      "dtype: object\n",
      "Weather data shape: (366, 151)\n",
      "STATION                 object\n",
      "DATE            datetime64[ns]\n",
      "ACMC                   float64\n",
      "ACMH                   float64\n",
      "ACSC                   float64\n",
      "                     ...      \n",
      "WV20                   float64\n",
      "alt                    float64\n",
      "station_info           float64\n",
      "station_name           float64\n",
      "time                   float64\n",
      "Length: 151, dtype: object\n",
      "Boroughs GeoDataFrame shape: (5, 5)\n",
      "BoroCode         int32\n",
      "BoroName        object\n",
      "Shape_Leng     float64\n",
      "Shape_Area     float64\n",
      "geometry      geometry\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Crime data shape:\", df_crime.shape)\n",
    "print(df_crime.dtypes)\n",
    "\n",
    "print(\"Weather data shape:\", df_weather.shape)\n",
    "print(df_weather.dtypes)\n",
    "\n",
    "print(\"Boroughs GeoDataFrame shape:\", gdf_boroughs.shape)\n",
    "print(gdf_boroughs.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb0ab25",
   "metadata": {},
   "source": [
    "\n",
    "### 3.2 Preview Samples\n",
    "\n",
    "Previewing a few rows offers an immediate look at real records, revealing formatting quirks and guiding early decisions on column selection, renaming, or basic transformations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4db24e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BoroCode</th>\n",
       "      <th>BoroName</th>\n",
       "      <th>Shape_Leng</th>\n",
       "      <th>Shape_Area</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>330385.03697</td>\n",
       "      <td>1.623853e+09</td>\n",
       "      <td>MULTIPOLYGON (((-74.05051 40.56642, -74.05047 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Queens</td>\n",
       "      <td>861038.47930</td>\n",
       "      <td>3.049947e+09</td>\n",
       "      <td>MULTIPOLYGON (((-73.83668 40.59495, -73.83678 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>726568.94634</td>\n",
       "      <td>1.959432e+09</td>\n",
       "      <td>MULTIPOLYGON (((-73.86706 40.58209, -73.86769 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>358532.95642</td>\n",
       "      <td>6.364422e+08</td>\n",
       "      <td>MULTIPOLYGON (((-74.01093 40.68449, -74.01193 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>464517.89055</td>\n",
       "      <td>1.186804e+09</td>\n",
       "      <td>MULTIPOLYGON (((-73.89681 40.79581, -73.89694 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BoroCode       BoroName    Shape_Leng    Shape_Area  \\\n",
       "0         5  Staten Island  330385.03697  1.623853e+09   \n",
       "1         4         Queens  861038.47930  3.049947e+09   \n",
       "2         3       Brooklyn  726568.94634  1.959432e+09   \n",
       "3         1      Manhattan  358532.95642  6.364422e+08   \n",
       "4         2          Bronx  464517.89055  1.186804e+09   \n",
       "\n",
       "                                            geometry  \n",
       "0  MULTIPOLYGON (((-74.05051 40.56642, -74.05047 ...  \n",
       "1  MULTIPOLYGON (((-73.83668 40.59495, -73.83678 ...  \n",
       "2  MULTIPOLYGON (((-73.86706 40.58209, -73.86769 ...  \n",
       "3  MULTIPOLYGON (((-74.01093 40.68449, -74.01193 ...  \n",
       "4  MULTIPOLYGON (((-73.89681 40.79581, -73.89694 ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display first rows of crime data\n",
    "df_crime.head()\n",
    "\n",
    "# Display first rows of weather data\n",
    "df_weather.head()\n",
    "\n",
    "# Display first rows of borough geometries\n",
    "gdf_boroughs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4106a5ea",
   "metadata": {},
   "source": [
    "### 3.3 Missing Values Check\n",
    "\n",
    "Understanding missing data is crucial in any real-world dataset. Here, we assess the extent of missingness in both crime and weather records. This step provides early insights into data quality, helps identify potential inconsistencies in data collection, and prepares us to choose appropriate handling techniques — such as imputation or exclusion — for the downstream analysis. Recruiters and real-world projects highly value this kind of diligence and data awareness, as it reflects a thoughtful and responsible data science mindset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "241ca632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ACMC    366\n",
       "ACSC    366\n",
       "ACMH    366\n",
       "ACSH    366\n",
       "DAPR    366\n",
       "       ... \n",
       "PRCP      0\n",
       "SNWD      0\n",
       "SNOW      0\n",
       "TMIN      0\n",
       "TMAX      0\n",
       "Length: 151, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count missing values in crime data\n",
    "df_crime.isna().sum().sort_values(ascending=False)\n",
    "\n",
    "# Count missing values in weather data\n",
    "df_weather.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aab86ac",
   "metadata": {},
   "source": [
    "## 4. Next Steps & Conclusions\n",
    "\n",
    "At this point, we’ve established a reproducible environment, loaded our core datasets, and performed an initial inspection. The insights gained here lay the groundwork for informed cleaning strategies, feature engineering, and subsequent exploratory analyses. Documenting each decision fosters transparency and trust—qualities that recruiters and collaborators highly appreciate.\n",
    "\n",
    "* Verify date columns for completeness and correctness.\n",
    "* Determine if filtering by year range or crime type is necessary.\n",
    "* Assess missing data and choose an appropriate strategy (e.g., imputation or removal).\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
