{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09c7a0e5",
   "metadata": {},
   "source": [
    "# Notebook 01 – Data Ingestion & Initial Exploration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e521292d",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Environment Setup\n",
    "\n",
    "Ensuring a clean and reproducible environment is fundamental. Here, we import the core libraries and set up our workspace so that anyone cloning this repo can replicate our analysis without compatibility issues.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9decd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential imports\n",
    "import pandas as pd\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f1eb97",
   "metadata": {},
   "source": [
    "# 2. Load Raw Data\n",
    "\n",
    "Loading raw datasets is the first critical step. By separating this phase, we maintain a clear pipeline: raw files remain untouched, enabling transparent version control and easy auditing of original sources.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84675124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Load NYPD crime data\n",
    "# Adjust column name 'CMPLNT_FR_DT' as needed\n",
    "df_crime = pd.read_csv(\n",
    "    '../data/raw/nypd_crime.csv',\n",
    "    parse_dates=['CMPLNT_FR_DT'],\n",
    "    dayfirst=False,\n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "# 2.2 Load NOAA weather data\n",
    "# Adjust column name 'DATE' as needed\n",
    "df_weather = pd.read_csv(\n",
    "    '../data/raw/noaa_weather.csv',\n",
    "    parse_dates=['DATE'],\n",
    "    dayfirst=False,\n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "# 2.3 Load NYC boroughs GeoJSON\n",
    "gdf_boroughs = gpd.read_file(\n",
    "    '../data/raw/nyc_boroughs.geojson'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a52bd4e",
   "metadata": {},
   "source": [
    "## 3. Initial Data Inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44be759",
   "metadata": {},
   "source": [
    "### 3.1 Data Types & Shapes\n",
    "\n",
    "Understanding the structure and scale of each dataset is key to planning the analysis. Checking data types and shapes helps identify conversion needs, memory constraints, and potential anomalies before diving deeper.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45484471",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Crime data shape:\", df_crime.shape)\n",
    "print(df_crime.dtypes)\n",
    "\n",
    "print(\"Weather data shape:\", df_weather.shape)\n",
    "print(df_weather.dtypes)\n",
    "\n",
    "print(\"Boroughs GeoDataFrame shape:\", gdf_boroughs.shape)\n",
    "print(gdf_boroughs.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb0ab25",
   "metadata": {},
   "source": [
    "\n",
    "### 3.2 Preview Samples\n",
    "\n",
    "Previewing a few rows offers an immediate look at real records, revealing formatting quirks and guiding early decisions on column selection, renaming, or basic transformations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db24e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first rows of crime data\n",
    "df_crime.head()\n",
    "\n",
    "# Display first rows of weather data\n",
    "df_weather.head()\n",
    "\n",
    "# Display first rows of borough geometries\n",
    "gdf_boroughs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4106a5ea",
   "metadata": {},
   "source": [
    "### 3.3 Missing Values Check\n",
    "\n",
    "Understanding missing data is crucial in any real-world dataset. Here, we assess the extent of missingness in both crime and weather records. This step provides early insights into data quality, helps identify potential inconsistencies in data collection, and prepares us to choose appropriate handling techniques — such as imputation or exclusion — for the downstream analysis. Recruiters and real-world projects highly value this kind of diligence and data awareness, as it reflects a thoughtful and responsible data science mindset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241ca632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count missing values in crime data\n",
    "df_crime.isna().sum().sort_values(ascending=False)\n",
    "\n",
    "# Count missing values in weather data\n",
    "df_weather.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aab86ac",
   "metadata": {},
   "source": [
    "## 4. Next Steps & Conclusions\n",
    "\n",
    "At this point, we’ve established a reproducible environment, loaded our core datasets, and performed an initial inspection. The insights gained here lay the groundwork for informed cleaning strategies, feature engineering, and subsequent exploratory analyses. Documenting each decision fosters transparency and trust—qualities that recruiters and collaborators highly appreciate.\n",
    "\n",
    "* Verify date columns for completeness and correctness.\n",
    "* Determine if filtering by year range or crime type is necessary.\n",
    "* Assess missing data and choose an appropriate strategy (e.g., imputation or removal).\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
